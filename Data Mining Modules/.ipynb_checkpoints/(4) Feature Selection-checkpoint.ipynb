{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "## Topics for this notebook\n",
    "### (Pearson correlation and chi square will not be covered in this notebook, see bivariate analysis) \n",
    "1. Spitting the data between training and testing sets\n",
    "2. Oversampling to make the training set more balanced  \n",
    "3. Feature selection using a wrapper method\n",
    "4. Feature selection using an embedded method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data frame into separate training and testing data frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splits the t dataframe into a training data frame and a testing data frame\n",
    "#the training data frame holds 75% of the data and the rest is in the testing data frame \n",
    "install.packages(\"caTools\")\n",
    "library(caTools)\n",
    "set.seed(123)   \n",
    "sample = sample.split(t,SplitRatio = 0.75) \n",
    "train1 =subset(t,sample ==TRUE) \n",
    "test1=subset(t, sample==FALSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversample the minority outcome to balance the training data frame (not always necessary)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oversampling minority outcome to correct for data imbalance\n",
    "install.packages(\"ROSE\")\n",
    "library(ROSE)\n",
    "data.rose <- ROSE(hospital_death~., p = 0.4, data=test1, seed=3)$data\n",
    "table(data.rose$hospital_death)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward feature selection using recursive feature elimination (wrapper method) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selection using recursive feature elimination(rfe) \n",
    "#backward feature selection starts with all features then reduces the number of features \n",
    "\n",
    "#establish training parameters\n",
    "rfe_training <- rfeControl(functions=rfFuncs, method=\"cv\", number=10)\n",
    "\n",
    "#run the rfe model using the oversampled training data \n",
    "rfe <- rfe(data.rose[,2:18], data.rose[,1], sizes=c(2:18), rfeControl=rfe_training)\n",
    "print(rfe)\n",
    "\n",
    "#show variable rank\n",
    "predictors(rfe) \n",
    "\n",
    "#display graph that highlights the most accurate number of features \n",
    "plot(rfe, type=c(\"g\", \"o\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection using a random forest algorithm (embedded method) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selection using a random forest algorithm \n",
    "#random forest is an embedded method that selects variables as part of building the model \n",
    "install.packages(“mlbench”)\n",
    "install.packages(“caret”)\n",
    "install.packages(“randomForest”)\n",
    "install.packages(“e1071”)\n",
    "library(e1071)\n",
    "library(mlbench)\n",
    "library(caret)\n",
    "library(randomForest)\n",
    "\n",
    "#establish the training parameters \n",
    "t_training<- trainControl(method = \"repeatedcv\", number=10, repeats=3)\n",
    "seed<- 7\n",
    "metric<- \"Accuracy\"\n",
    "set.seed(seed)\n",
    "mtry<- sqrt(ncol(data.rose))\n",
    "tunegrid<-expand.grid(.mtry=mtry)\n",
    "\n",
    "#train the random forest algorithm on the oversampled training data \n",
    "t_model<- train(hospital_death~., data=data.rose, method=\"rf\", metric=metric, tuneGrid=tunegrid, trControl=t_training)\n",
    "\n",
    "#show the results of model training\n",
    "print(t_model)\n",
    "\n",
    "#apply the trained model to the unseen testing data frame and store the results as z  \n",
    "z<- predict(t_model, test1)\n",
    "\n",
    "#look at the results of running the model with unseen test data using a confusion matrix \n",
    "confusionMatrix(z, test1$hospital_death)\n",
    "\n",
    "#visualize variable importance \n",
    "variable_importance<- varImp(t_model)\n",
    "print(variable_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This concludes the feature selection part of the course\n",
    "- The following key questions were addressed during this notebook and the accompanying video lecture:\n",
    "1. What are the three main types of methods used for feature selection?\n",
    "2. What are the advantages and disadvantages of the feature selection approaches mentioned?\n",
    "\n",
    " \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
